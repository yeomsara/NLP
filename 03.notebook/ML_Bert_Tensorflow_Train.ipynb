{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469a4b87-8c22-4414-ab73-46c244cd6a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T15:10:48.480152Z",
     "iopub.status.busy": "2021-07-17T15:10:48.479971Z",
     "iopub.status.idle": "2021-07-17T15:10:50.908501Z",
     "shell.execute_reply": "2021-07-17T15:10:50.907903Z",
     "shell.execute_reply.started": "2021-07-17T15:10:48.480099Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ez-flow/big_data/python/')\n",
    "import bigquery_etl as bq\n",
    "import confusion_matrix_customized as cm_customize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9bdac2-043e-401b-b899-e4180d4f0362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T15:10:50.909395Z",
     "iopub.status.busy": "2021-07-17T15:10:50.909225Z",
     "iopub.status.idle": "2021-07-17T15:10:55.121002Z",
     "shell.execute_reply": "2021-07-17T15:10:55.120498Z",
     "shell.execute_reply.started": "2021-07-17T15:10:50.909377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16407, 3)\n"
     ]
    }
   ],
   "source": [
    "## (Setp 1-1) Load Data\n",
    "def convert_lowercase(df):\n",
    "    df_1 =  df.apply(lambda x: x.astype(str).str.lower() if(x.dtype == 'object') else x)\n",
    "    upper_list = ['reviewId','asin','size','cmpl_fc1_cd']\n",
    "    cols = list(set(upper_list)& set(df_1.columns))\n",
    "    df_1[cols] = df_1[cols].apply(lambda x: x.astype(str).str.upper() if(x.dtype == 'object') else x)\n",
    "    return df_1\n",
    "\n",
    "bert_train_sql = '''\n",
    "            SELECT *\n",
    "            FROM taxonomy.bert_train_input_reviews\n",
    "            '''\n",
    "df   = convert_lowercase(bq.select_query(bert_train_sql))\n",
    "df   = df[['reviewId','review_text','cmpl_fc1']].drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d14116-1fe4-457c-ad3a-f65f21164619",
   "metadata": {},
   "source": [
    "# make Label Dictionary (priority-> class number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96aa1073-73f5-42cd-9a45-5e96ddc85fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-17T15:12:07.097438Z",
     "iopub.status.busy": "2021-07-17T15:12:07.097215Z",
     "iopub.status.idle": "2021-07-17T15:12:07.119963Z",
     "shell.execute_reply": "2021-07-17T15:12:07.119448Z",
     "shell.execute_reply.started": "2021-07-17T15:12:07.097417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##(Step 1-2) Load complain factor priority and label\n",
    "## make Label Dictionary (priority-> class number)\n",
    "label_dict = {  'recovery'        : 0, \n",
    "                'durability'      : 1,\n",
    "                'defect'          : 2, \n",
    "                'too hard'        : 3,  \n",
    "                'too soft'        : 4, \n",
    "                'missing parts'   : 5,\n",
    "                'odor'            : 6,\n",
    "                'sound'           : 7,\n",
    "                'uncomfortable'   : 8,\n",
    "                'size issue'      : 9,\n",
    "                'shipping damage' : 10,\n",
    "                'delivery'        : 11,\n",
    "                'fiberglass'      : 12,\n",
    "                'hard to set up'  : 13, \n",
    "                'slipping'        : 14, \n",
    "                'cover issue'     : 15, \n",
    "                'customer service': 16, \n",
    "                'springs felt'    : 17,\n",
    "                'overall quality' : 18,\n",
    "                'no support'      : 19,\n",
    "                'customer error'  : 20,\n",
    "                'structure design': 21,\n",
    "                'others'          : 22, \n",
    "           }\n",
    "\n",
    "df['label'] = df['cmpl_fc1']\n",
    "df = df.replace({'label':label_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f104e0-f914-4de9-ae04-670ad1b6a24a",
   "metadata": {},
   "source": [
    "# Split Train / Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "039422d7-b679-4b3f-aefb-02706e092036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:47:11.797322Z",
     "iopub.status.busy": "2021-07-06T13:47:11.797119Z",
     "iopub.status.idle": "2021-07-06T13:47:11.856072Z",
     "shell.execute_reply": "2021-07-06T13:47:11.855580Z",
     "shell.execute_reply.started": "2021-07-06T13:47:11.797301Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##(Step 2-1) Split Train / Test set \n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.cmpl_fc1.values, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.cmpl_fc1.values)\n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "df['label'] = df['cmpl_fc1']\n",
    "df = df.replace({'label':label_dict})\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type']   = 'val'\n",
    "print(df.groupby(['cmpl_fc1', 'label', 'data_type'])['review_text'].count().reset_index().sort_values(['label','data_type'],ascending=[True,True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea36334-c5c2-49b9-88bf-83a50a793b4c",
   "metadata": {},
   "source": [
    "# Encoded Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "bf9561db-027b-492d-945e-0683e88c23aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:12.218204Z",
     "iopub.status.busy": "2021-07-06T13:48:12.217989Z",
     "iopub.status.idle": "2021-07-06T13:48:30.286629Z",
     "shell.execute_reply": "2021-07-06T13:48:30.285972Z",
     "shell.execute_reply.started": "2021-07-06T13:48:12.218173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/jupyterhub/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##(Step 3-1) Encoded Bert Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b59d26-9aea-44bd-8b38-ffe02b1b099b",
   "metadata": {},
   "source": [
    "# Make Bert Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0a585bde-555a-4d7f-b912-901a2a4fc572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:30.287724Z",
     "iopub.status.busy": "2021-07-06T13:48:30.287565Z",
     "iopub.status.idle": "2021-07-06T13:48:30.290304Z",
     "shell.execute_reply": "2021-07-06T13:48:30.289898Z",
     "shell.execute_reply.started": "2021-07-06T13:48:30.287707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## (Step 4-1) Make Bert input Dataset \n",
    "## hyper parameter  'batch size' default '5'\n",
    "batch_size = 5\n",
    "\n",
    "dataloader_train      = DataLoader(dataset_train, \n",
    "                                  sampler=RandomSampler(dataset_train), \n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                  sampler=SequentialSampler(dataset_val), \n",
    "                                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3e914-c950-4ca7-8b84-7a610c2ee9a0",
   "metadata": {},
   "source": [
    "# BertModel - bertbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e568dc84-b3f9-4911-b928-c74e9ae6dfa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:30.291249Z",
     "iopub.status.busy": "2021-07-06T13:48:30.291074Z",
     "iopub.status.idle": "2021-07-06T13:48:34.823009Z",
     "shell.execute_reply": "2021-07-06T13:48:34.822551Z",
     "shell.execute_reply.started": "2021-07-06T13:48:30.291233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## (Step 5-1) Bert Model - Bertbase-uncased \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9644a28-751c-42bc-94f2-63cff7dc5e97",
   "metadata": {},
   "source": [
    "# Optimizaion Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "52f3d03e-66e5-4145-9791-4f0126f4d768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:38.623616Z",
     "iopub.status.busy": "2021-07-06T13:48:38.623407Z",
     "iopub.status.idle": "2021-07-06T13:48:38.627498Z",
     "shell.execute_reply": "2021-07-06T13:48:38.627076Z",
     "shell.execute_reply.started": "2021-07-06T13:48:38.623596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## (Step 6-1) Optimization Bert ( Adam Optimizer)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "## (Step 6-2) Hyper parameter 'Epochs' default 5                 \n",
    "epochs    = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316e2d4-0da3-479b-bc29-13c936ed344f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-30T08:54:27.164659Z",
     "iopub.status.busy": "2021-06-30T08:54:27.164451Z",
     "iopub.status.idle": "2021-06-30T08:54:27.168654Z",
     "shell.execute_reply": "2021-06-30T08:54:27.168255Z",
     "shell.execute_reply.started": "2021-06-30T08:54:27.164638Z"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Function model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "65ecfa53-66df-401d-8830-a9b1de612478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:42.162175Z",
     "iopub.status.busy": "2021-07-06T13:48:42.161973Z",
     "iopub.status.idle": "2021-07-06T13:48:42.168311Z",
     "shell.execute_reply": "2021-07-06T13:48:42.167878Z",
     "shell.execute_reply.started": "2021-07-06T13:48:42.162155Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## (Step 7-1) Evaluate Function model performance\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050f528-39ae-434a-b82e-1f7abd392aa7",
   "metadata": {},
   "source": [
    "# Train Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bec9ad1f-5567-43a3-bdbe-8266efa749ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T13:48:57.720805Z",
     "iopub.status.busy": "2021-07-06T13:48:57.720590Z",
     "iopub.status.idle": "2021-07-06T21:23:14.689971Z",
     "shell.execute_reply": "2021-07-06T21:23:14.689334Z",
     "shell.execute_reply.started": "2021-07-06T13:48:57.720785Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd0841919c148bfb4ddb60a67ee71e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.768855391512072\n",
      "Validation loss: 1.293726212779681\n",
      "F1 Score (Weighted): 0.6029686681079964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 1.1502682848363945\n",
      "Validation loss: 1.2176828917925773\n",
      "F1 Score (Weighted): 0.6238240057862128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.9274944996628904\n",
      "Validation loss: 1.2118226965214463\n",
      "F1 Score (Weighted): 0.6190196979545188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.7837688199793761\n",
      "Validation loss: 1.307875133726908\n",
      "F1 Score (Weighted): 0.6150342074656724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.6719211910213488\n",
      "Validation loss: 1.3995930333851256\n",
      "F1 Score (Weighted): 0.6033102699322258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 0.5825581417372903\n",
      "Validation loss: 1.5368820448392544\n",
      "F1 Score (Weighted): 0.5942500894734635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 0.5131978827973285\n",
      "Validation loss: 1.6291928634317456\n",
      "F1 Score (Weighted): 0.5951507910912768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/2989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Training loss: 0.46755418215008054\n",
      "Validation loss: 1.683635844996172\n",
      "F1 Score (Weighted): 0.5903713108748617\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'/home/ez-flow/big_data/model/CF_Bert_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521ba2b-1298-40f9-a57b-67be6b038968",
   "metadata": {},
   "source": [
    "# Evaluate (Testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020e6905-4323-4bd9-8eaa-3ca069acfecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T08:44:14.797567Z",
     "iopub.status.busy": "2021-07-13T08:44:14.797356Z",
     "iopub.status.idle": "2021-07-13T08:44:14.803093Z",
     "shell.execute_reply": "2021-07-13T08:44:14.802647Z",
     "shell.execute_reply.started": "2021-07-13T08:44:14.797547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,plot_confusion_matrix,confusion_matrix,accuracy_score\n",
    "import confusion_matrix_customized as cm_customize\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    print(label_dict_inverse)\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "        \n",
    "def make_confusion_matrix_customized(y_true,y_pred):\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    print('================================== Evaluation Report ==================================')\n",
    "    print(classification_report(y_true, y_pred,target_names=label_dict))\n",
    "    print('======================================================================================')\n",
    "    cm_customize._execute_confusion_matrix(y_true,y_pred,'Bert',label_dict)\n",
    "    accuracy_score(y_true,y_pred)\n",
    "    \n",
    "    \n",
    "def opt_convert_predict_class(preds):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    print(label_dict_inverse)\n",
    "    preds_flat  = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    return preds_flat\n",
    "    \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "## you should modify champion model directory \n",
    "model_dir = '/home/ez-flow/big_data/model/CF_Bert_Operation.model'\n",
    "model.load_state_dict(torch.load(model_dir, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "y_pred = opt_convert_predict_class(predictions)\n",
    "y_true = true_vals\n",
    "make_confusion_matrix_customized(y_true,y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
